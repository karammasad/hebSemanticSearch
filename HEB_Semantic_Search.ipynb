{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iwuF05pdN54"
      },
      "outputs": [],
      "source": [
        "!pip -q install numpy pandas tqdm sentence-transformers\n",
        "# Optional but recommended for speed; if it fails, the code will still work with the NumPy fallback.\n",
        "!pip -q install faiss-cpu || echo \"FAISS install failed; will use NumPy fallback.\"\n",
        "# If you plan to use OpenAI embeddings later:\n",
        "!pip -q install openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYA-wmdlfSTe"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "import json, re\n",
        "from pathlib import Path\n",
        "from typing import Iterable, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f6485db",
        "outputId": "434914de-3d5f-46bb-8e87-d6757935eacd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPEN_API_KEY loaded into environment variables.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Retrieve the API key from Colab secrets\n",
        "OPEN_API_KEY = userdata.get('OPEN_API_KEY')\n",
        "\n",
        "# Set it as an environment variable\n",
        "os.environ['OPEN_API_KEY'] = OPEN_API_KEY\n",
        "\n",
        "print(\"OPEN_API_KEY loaded into environment variables.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fXiZWCPed_H"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import faiss   # from faiss-cpu\n",
        "    FAISS_AVAILABLE = True\n",
        "except Exception:\n",
        "    faiss = None\n",
        "    FAISS_AVAILABLE = False\n",
        "\n",
        "def build_ip_index(emb: np.ndarray):\n",
        "    \"\"\"\n",
        "    Inner-product index. If FAISS is present, use it; otherwise a NumPy fallback\n",
        "    with the same .search(Q, k) API. Assumes emb are L2-normalized.\n",
        "    \"\"\"\n",
        "    if FAISS_AVAILABLE:\n",
        "        d = emb.shape[1]\n",
        "        index = faiss.IndexFlatIP(d)\n",
        "        index.add(emb.astype(\"float32\"))\n",
        "        return index\n",
        "\n",
        "    class NumpyIPIndex:\n",
        "        def __init__(self, X):\n",
        "            self.X = X.astype(\"float32\")\n",
        "        def add(self, X):\n",
        "            pass\n",
        "        def search(self, Q, k):\n",
        "            S = Q @ self.X.T\n",
        "            I = np.argpartition(-S, k-1, axis=1)[:, :k]\n",
        "            S_topk = np.take_along_axis(S, I, axis=1)\n",
        "            order = np.argsort(-S_topk, axis=1)\n",
        "            I_sorted = np.take_along_axis(I, order, axis=1)\n",
        "            D_sorted = np.take_along_axis(S_topk, order, axis=1)\n",
        "            return D_sorted.astype(\"float32\"), I_sorted.astype(\"int64\")\n",
        "    return NumpyIPIndex(emb)\n",
        "\n",
        "def save_faiss_index(index, path: Path):\n",
        "    if FAISS_AVAILABLE:\n",
        "        faiss.write_index(index, str(path))\n",
        "    else:\n",
        "        # NumPy fallback is in-memory only; nothing to save.\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wb0bkRUzjZWu"
      },
      "outputs": [],
      "source": [
        "def resolve_existing_file(preferred: str, keywords=(\"products\",), exts=(\".json\", \".jsonl\")) -> Path:\n",
        "    \"\"\"\n",
        "    Try preferred; else search CWD, /content (Colab), and /mnt/data (uploaded in ChatGPT)\n",
        "    for filenames containing all keywords and ending with one of exts.\n",
        "    \"\"\"\n",
        "    cand = Path(preferred)\n",
        "    if cand.exists():\n",
        "        return cand\n",
        "\n",
        "    search_roots = [Path(\".\"), Path(\"/content\"), Path(\"/mnt/data\")]\n",
        "    for root in search_roots:\n",
        "        if not root.exists():\n",
        "            continue\n",
        "        for ext in exts:\n",
        "            for p in root.rglob(f\"*{ext}\"):\n",
        "                if all(k.lower() in p.name.lower() for k in keywords):\n",
        "                    return p\n",
        "\n",
        "    raise FileNotFoundError(\n",
        "        f\"Could not find products file. Tried '{preferred}' and searched CWD, /content, /mnt/data \"\n",
        "        f\"for {keywords} with exts {exts}.\"\n",
        "    )\n",
        "\n",
        "def load_products_any(products_path_hint: str = \"products.json\") -> list[dict]:\n",
        "    \"\"\"\n",
        "    Load products from JSON array, {'products': [...]}, or JSONL.\n",
        "    \"\"\"\n",
        "    fp = resolve_existing_file(products_path_hint, keywords=(\"products\",), exts=(\".json\", \".jsonl\"))\n",
        "    # Try JSON array/dict\n",
        "    try:\n",
        "        with open(fp, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "        if isinstance(data, list):\n",
        "            return data\n",
        "        if isinstance(data, dict) and \"products\" in data:\n",
        "            return data[\"products\"]\n",
        "    except json.JSONDecodeError:\n",
        "        pass\n",
        "    # Fallback: JSON Lines\n",
        "    items = []\n",
        "    with open(fp, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                items.append(json.loads(line))\n",
        "    return items\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18t783A4ko3Q"
      },
      "outputs": [],
      "source": [
        "from typing import Iterable, List # Import Iterable\n",
        "\n",
        "def norm_text(s: str) -> str:\n",
        "    s = (s or \"\").lower()\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    s = re.sub(r\"[^a-z0-9%\\. ]+\", \" \", s)\n",
        "\n",
        "    # Add stopword removal\n",
        "    stopwords = set([\"a\", \"an\", \"the\", \"and\", \"is\", \"in\", \"it\", \"to\", \"for\", \"with\", \"on\", \"this\", \"that\"]) # Add more stopwords as needed\n",
        "    words = s.split()\n",
        "    s = \" \".join([word for word in words if word not in stopwords])\n",
        "\n",
        "    return s.strip()\n",
        "\n",
        "def batch_embed(texts: Iterable[str], embed_fn, batch_size: int = 512) -> np.ndarray:\n",
        "    texts = list(texts)\n",
        "    out = []\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Embedding\", unit=\"batch\"):\n",
        "        out.append(embed_fn(texts[i:i+batch_size]))\n",
        "    return np.vstack(out) if out else np.zeros((0, 384), dtype=\"float32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJC6d1auksBW"
      },
      "outputs": [],
      "source": [
        "def build_vector_store(\n",
        "    products_json_path: str = \"products.json\",   # a hint; loader will auto-find\n",
        "    out_dir: str = \"vector_store\",\n",
        "    use_openai: bool = False\n",
        "):\n",
        "    out = Path(out_dir)\n",
        "    out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # 1) Load products\n",
        "    products = load_products_any(products_json_path)\n",
        "    if not products:\n",
        "        raise ValueError(\"No products loaded. Check your products file.\")\n",
        "\n",
        "    # 2) Canonicalize & normalize\n",
        "    rows = []\n",
        "    for r in products:\n",
        "        pid = str(r.get(\"product_id\") or r.get(\"id\") or r.get(\"sku\") or \"\")\n",
        "        title = r.get(\"title\") or r.get(\"name\") or \"\"\n",
        "        brand = r.get(\"brand\") or \"\"\n",
        "        category = r.get(\"category_path\") or r.get(\"category\") or \"\"\n",
        "        desc = r.get(\"description\") or \"\"\n",
        "        rows.append({\n",
        "            \"product_id\": pid,\n",
        "            \"title\": title,\n",
        "            \"brand\": brand,\n",
        "            \"category_path\": category,\n",
        "            \"description\": desc,\n",
        "            \"norm_title\": norm_text(title),\n",
        "            \"norm_brand\": norm_text(brand),\n",
        "            \"norm_category\": norm_text(category),\n",
        "            \"norm_description\": norm_text(desc),\n",
        "        })\n",
        "    df = pd.DataFrame(rows)\n",
        "    df.to_parquet(out / \"products.parquet\", index=False)\n",
        "\n",
        "    # 3) Choose embedding fn\n",
        "    embed_fn = embed_texts_openai\n",
        "\n",
        "    # 4) Per-field embeddings\n",
        "    print(\"Embedding title...\")\n",
        "    emb_title = batch_embed(df[\"norm_title\"].fillna(\"\").astype(str).tolist(), embed_fn)\n",
        "    print(\"Embedding brand...\")\n",
        "    emb_brand = batch_embed(df[\"norm_brand\"].fillna(\"\").astype(str).tolist(), embed_fn)\n",
        "    print(\"Embedding category...\")\n",
        "    emb_cat   = batch_embed(df[\"norm_category\"].fillna(\"\").astype(str).tolist(), embed_fn)\n",
        "    print(\"Embedding description...\")\n",
        "    emb_desc  = batch_embed(df[\"norm_description\"].fillna(\"\").astype(str).tolist(), embed_fn)\n",
        "\n",
        "    # 5) Concatenate embeddings\n",
        "    print(\"Concatenating embeddings...\")\n",
        "    emb_combined = np.concatenate([emb_title, emb_brand, emb_cat, emb_desc], axis=1)\n",
        "\n",
        "    # 6) Save combined embeddings\n",
        "    np.save(out / \"emb_combined.npy\", emb_combined)\n",
        "\n",
        "    # 7) Build index (FAISS or NumPy fallback)\n",
        "    print(\"Building combined index (FAISS available? ->\", FAISS_AVAILABLE, \")\")\n",
        "    idx_combined = build_ip_index(emb_combined)\n",
        "\n",
        "    # 8) Save FAISS index if present\n",
        "    if FAISS_AVAILABLE:\n",
        "        save_faiss_index(idx_combined, out / \"index_combined.faiss\")\n",
        "    else:\n",
        "        print(\"FAISS not installed: skipping .faiss file (NumPy fallback will be used at query time).\")\n",
        "\n",
        "    # 9) Row → product_id map\n",
        "    pid_map = df[\"product_id\"].astype(str).tolist()\n",
        "    pd.Series(pid_map).to_json(out / \"rowid_to_pid.json\", orient=\"values\")\n",
        "\n",
        "    print(\"✅ Finished Step 1. Vector store written to:\", out.resolve())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLWYm1IakvT9",
        "outputId": "efbae0f1-fe37-4602-9508-bff32af75370"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CWD: /content\n",
            "Found candidates:\n",
            "No products*.json/.jsonl files found in CWD or /content.\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "print(\"CWD:\", Path.cwd())\n",
        "candidates = []\n",
        "for root in [Path(\".\"), Path(\"/content\")]:\n",
        "    if root.exists():\n",
        "        for p in root.rglob(\"products*.json*\"):\n",
        "            candidates.append(p.resolve())\n",
        "\n",
        "print(\"Found candidates:\")\n",
        "for c in candidates:\n",
        "    print(\" -\", c)\n",
        "\n",
        "if not candidates:\n",
        "    print(\"No products*.json/.jsonl files found in CWD or /content.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "4FXb1l50lFBg",
        "outputId": "afb61a06-79f8-4e88-bb73-50023a6d8c66"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-80161d40-e94f-47b9-9900-48df68324d67\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-80161d40-e94f-47b9-9900-48df68324d67\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving products.json to products.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['products.json']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "up = files.upload()  # choose your products.json or products.jsonl\n",
        "list(up.keys())      # shows uploaded filename(s)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9pmF22LH1ua"
      },
      "outputs": [],
      "source": [
        "# Re-define OpenAI client and embedding function if not already in the current kernel state\n",
        "_OPENAI_CLIENT = None\n",
        "def get_openai_client():\n",
        "     global _OPENAI_CLIENT\n",
        "     if _OPENAI_CLIENT is None:\n",
        "         _OPENAI_CLIENT = OpenAI(api_key=os.environ[\"OPEN_API_KEY\"])\n",
        "     return _OPENAI_CLIENT\n",
        "\n",
        "def embed_texts_openai(texts: List[str], model: str = \"text-embedding-3-large\") -> np.ndarray:\n",
        "     client = get_openai_client()\n",
        "     # Replace empty strings with a single space to avoid OpenAI API errors\n",
        "     processed_texts = [t if t.strip() != \"\" else \" \" for t in texts]\n",
        "     resp = client.embeddings.create(model=model, input=processed_texts)\n",
        "     V = np.array([d.embedding for d in resp.data], dtype=\"float32\")\n",
        "     V /= (np.linalg.norm(V, axis=1, keepdims=True) + 1e-12)\n",
        "     return V.astype(\"float32\")\n",
        "\n",
        "from openai import OpenAI # Import OpenAI class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwa3GVVllOzA",
        "outputId": "8b4bb2ad-4059-44d4-ccfb-c08440ab1c84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding title...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Embedding: 100%|██████████| 7/7 [00:12<00:00,  1.72s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding brand...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Embedding: 100%|██████████| 7/7 [00:09<00:00,  1.43s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding category...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Embedding: 100%|██████████| 7/7 [00:08<00:00,  1.27s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding description...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Embedding: 100%|██████████| 7/7 [00:11<00:00,  1.68s/batch]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Concatenating embeddings...\n",
            "Building combined index (FAISS available? -> True )\n",
            "✅ Finished Step 1. Vector store written to: /content/vector_store\n"
          ]
        }
      ],
      "source": [
        "# EXAMPLES — pick ONE that matches your file\n",
        "# products_path = \"/content/products.json\"\n",
        "# products_path = \"/content/products.jsonl\"\n",
        "# products_path = \"/content/drive/MyDrive/datathon/products.json\"\n",
        "\n",
        "products_path = \"/content/products.json\"   # <- CHANGE THIS to your real path\n",
        "\n",
        "build_vector_store(\n",
        "    products_json_path=products_path,\n",
        "    out_dir=\"vector_store\",\n",
        "    use_openai=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3e--3gBloMw"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np, json, pandas as pd\n",
        "\n",
        "root = Path(\"vector_store\")\n",
        "print(\"Files:\", [p.name for p in root.iterdir()])\n",
        "print(\"emb_combined.npy shape:\", np.load(root/\"emb_combined.npy\").shape)\n",
        "print(\"rowid_to_pid.json length:\", len(json.loads((root/\"rowid_to_pid.json\").read_text())))\n",
        "pd.read_parquet(root/\"products.parquet\").head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvnJNllMmxgT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "root = Path(\"vector_store\")\n",
        "if (root / \"products.parquet\").exists():\n",
        "    print(\"Head of products.parquet:\")\n",
        "    print(pd.read_parquet(root / \"products.parquet\").head())\n",
        "else:\n",
        "    print(f\"products.parquet not found in {root}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbwepdm0k8JZ"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import json, numpy as np\n",
        "import pandas as pd # Import pandas for displaying dataframe\n",
        "\n",
        "root = Path(\"vector_store\")\n",
        "\n",
        "if not root.exists():\n",
        "    print(f\"Error: Directory {root} not found.\")\n",
        "elif not list(root.iterdir()):\n",
        "    print(f\"Error: Directory {root} is empty.\")\n",
        "else:\n",
        "    print(f\"Files in {root}:\")\n",
        "    for p in root.iterdir():\n",
        "        print(\" -\", p.name)\n",
        "\n",
        "    # Check shapes of all embedding files\n",
        "    embedding_files = {\n",
        "        \"title\": \"emb_title.npy\",\n",
        "        \"brand\": \"emb_brand.npy\",\n",
        "        \"category\": \"emb_category.npy\",\n",
        "        \"description\": \"emb_description.npy\",\n",
        "    }\n",
        "\n",
        "    for name, filename in embedding_files.items():\n",
        "        file_path = root / filename\n",
        "        if file_path.exists():\n",
        "            E = np.load(file_path)\n",
        "            print(f\"Embeddings shape ({name}): {E.shape}\")\n",
        "        else:\n",
        "            print(f\"Embedding file not found: {file_path}\")\n",
        "\n",
        "    # Load pid map and peek at product metadata\n",
        "    pid_map_path = root / \"rowid_to_pid.json\"\n",
        "    if pid_map_path.exists():\n",
        "        pid_map = json.loads(pid_map_path.read_text())\n",
        "        print(\"Products indexed:\", len(pid_map))\n",
        "    else:\n",
        "        print(f\"Product ID map not found: {pid_map_path}\")\n",
        "\n",
        "    products_parquet_path = root / \"products.parquet\"\n",
        "    if products_parquet_path.exists():\n",
        "        meta = pd.read_parquet(products_parquet_path).head(3)\n",
        "        print(\"\\nHead of products.parquet:\")\n",
        "        display(meta)\n",
        "    else:\n",
        "        print(f\"products.parquet not found: {products_parquet_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBmxsSpFodU-"
      },
      "outputs": [],
      "source": [
        "VSTORE = Path(\"vector_store\")  # change if you saved elsewhere\n",
        "\n",
        "# Load combined embeddings\n",
        "E_combined = np.load(VSTORE/\"emb_combined.npy\")\n",
        "\n",
        "# Build in-memory IP index (fast; a few seconds)\n",
        "IDX_combined = build_ip_index(E_combined)\n",
        "\n",
        "# Load ID map and metadata\n",
        "rowid_to_pid = json.loads((VSTORE/\"rowid_to_pid.json\").read_text())\n",
        "meta = pd.read_parquet(VSTORE/\"products.parquet\")\n",
        "pid_to_row = {pid: i for i, pid in enumerate(rowid_to_pid)}\n",
        "\n",
        "len(rowid_to_pid), meta.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63efaW0HovGf"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "up = files.upload()  # pick your queries file, e.g., queries_synth_train.json\n",
        "list(up.keys())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXdeI3Uuoxbq",
        "outputId": "f8f07000-b15c-4a85-ba3b-84c63ee399de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total queries: 288\n",
            "[{'query_id': 's334', 'query': 'hearty organic soups for dinner'}, {'query_id': 's255', 'query': 'versatile cut chicken for grilling'}]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Assuming find_queries_file and QPATH are defined in a previous cell\n",
        "# If not, they should be included in this cell or ensured from prior cells.\n",
        "\n",
        "\n",
        "def load_queries_any(path):\n",
        "    path = Path(path)\n",
        "    # try JSON (array or dict)\n",
        "    try:\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "        if isinstance(data, list):\n",
        "            items = data\n",
        "        elif isinstance(data, dict) and \"queries\" in data:\n",
        "            items = data[\"queries\"]\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported JSON structure\")\n",
        "    except json.JSONDecodeError:\n",
        "        # JSONL fallback\n",
        "        items = []\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in line:\n",
        "                line = line.strip()\n",
        "                if line:\n",
        "                    items.append(json.loads(line))\n",
        "\n",
        "    # normalize keys\n",
        "    norm = []\n",
        "    for j in items:\n",
        "        qid = j.get(\"query_id\") or j.get(\"qid\") or j.get(\"id\")\n",
        "        qtext = j.get(\"query\") or j.get(\"text\")\n",
        "        if qid is None or qtext is None:\n",
        "            continue\n",
        "        norm.append({\"query_id\": str(qid), \"query\": str(qtext)})\n",
        "    return norm\n",
        "\n",
        "# Use the path found in Box 3A:\n",
        "QPATH = \"/content/queries_synth_train.json\"\n",
        "queries = load_queries_any(QPATH)\n",
        "print(\"Total queries:\", len(queries))\n",
        "print(queries[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN5tmfuaD3xM",
        "outputId": "1cd38099-dc77-4159-d93c-0768e295c613"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Queries file: /content/queries_synth_train.json\n",
            "Total queries: 288\n",
            "[{'query_id': 's334', 'query': 'hearty organic soups for dinner'}, {'query_id': 's255', 'query': 'versatile cut chicken for grilling'}, {'query_id': 's245', 'query': 'quick cook pork steaks'}]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "def find_queries_file(preferred=\"queries_synth_train.json\"):\n",
        "    roots = [Path(\".\"), Path(\"/content\"), Path(\"/mnt/data\")]\n",
        "    p = Path(preferred)\n",
        "    if p.exists():\n",
        "        return p.resolve()\n",
        "    for r in roots:\n",
        "        if not r.exists():\n",
        "            continue\n",
        "        for cand in r.rglob(\"queries_synth_test*.*json*\"):\n",
        "            return cand.resolve()\n",
        "    raise FileNotFoundError(\"Couldn't find queries_synth_test*.json — upload it or pass the exact path.\")\n",
        "\n",
        "QPATH = find_queries_file()  # auto-discovers, including `/mnt/data/queries_synth_train (2).json`\n",
        "print(\"Queries file:\", QPATH)\n",
        "\n",
        "# Load as [{\"query_id\": \"...\", \"query\": \"...\"}]\n",
        "with open(QPATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    queries_raw = json.load(f)\n",
        "\n",
        "queries = []\n",
        "for j in queries_raw:\n",
        "    qid = j.get(\"query_id\") or j.get(\"qid\") or j.get(\"id\")\n",
        "    qtx = j.get(\"query\") or j.get(\"text\")\n",
        "    if qid and qtx:\n",
        "        queries.append({\"query_id\": str(qid), \"query\": str(qtx)})\n",
        "\n",
        "print(\"Total queries:\", len(queries))\n",
        "print(queries[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJ8O2ba5Qgcv",
        "outputId": "2ed7c4f1-888f-41fb-8b52-30ebbadf9d72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-1.1.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (0.28.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (6.0.3)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.5.4)\n",
            "Collecting typer-slim (from huggingface_hub)\n",
            "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->huggingface_hub) (1.3.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface_hub) (8.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U sentence-transformers huggingface_hub transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7kTKhLjQpb-"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "# Choose a different pre-trained cross-encoder model\n",
        "cross_encoder_model_name = 'cross-encoder/ms-marco-MiniLM-L-6-v2' # Corrected model name\n",
        "\n",
        "# Instantiate the CrossEncoder model\n",
        "cross_encoder_model = CrossEncoder(cross_encoder_model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0daef62e"
      },
      "outputs": [],
      "source": [
        "# Instantiate the CrossEncoder model with the corrected name\n",
        "cross_encoder_model = CrossEncoder(cross_encoder_model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "lBQv3j6_RcC2",
        "outputId": "83af5439-d8d7-411a-849d-9a264865b9be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPEN_API_KEY loaded into environment variables.\n",
            "Queries file: /content/queries_synth_train.json\n",
            "Total queries: 288\n",
            "[{'query_id': 's334', 'query': 'hearty organic soups for dinner'}, {'query_id': 's255', 'query': 'versatile cut chicken for grilling'}, {'query_id': 's245', 'query': 'quick cook pork steaks'}]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"display(pd\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"product_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"10438511\",\n          \"1728261\",\n          \"497561\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"H-E-B Italian-Style Wedding Soup\",\n          \"H-E-B Organics Chicken Noodle Soup\",\n          \"Hill Country Fare Chunky Chicken Corn Chowder Soup\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"brand\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Hill Country Fare\",\n          \"H-E-B\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Pantry -> Soups & chili\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0166620507669273,\n        \"min\": 1.5441118478775024,\n        \"max\": 5.999448299407959,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.6501597166061401\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-981635f4-f1dd-4b9e-8a04-d2a9878a9241\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>name</th>\n",
              "      <th>brand</th>\n",
              "      <th>category</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1728263</td>\n",
              "      <td>H-E-B Organics Tomato Basil Soup</td>\n",
              "      <td>H-E-B</td>\n",
              "      <td>Pantry -&gt; Soups &amp; chili</td>\n",
              "      <td>5.999448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1728261</td>\n",
              "      <td>H-E-B Organics Chicken Noodle Soup</td>\n",
              "      <td>H-E-B</td>\n",
              "      <td>Pantry -&gt; Soups &amp; chili</td>\n",
              "      <td>5.985342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1728279</td>\n",
              "      <td>H-E-B Organics Southwest Style Black Bean Soup</td>\n",
              "      <td>H-E-B</td>\n",
              "      <td>Pantry -&gt; Soups &amp; chili</td>\n",
              "      <td>5.878461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1728270</td>\n",
              "      <td>H-E-B Organics Lentil Soup</td>\n",
              "      <td>H-E-B</td>\n",
              "      <td>Pantry -&gt; Soups &amp; chili</td>\n",
              "      <td>5.432003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5851502</td>\n",
              "      <td>H-E-B Hearty Wrangler Soup</td>\n",
              "      <td>H-E-B</td>\n",
              "      <td>Pantry -&gt; Soups &amp; chili</td>\n",
              "      <td>3.576779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>497561</td>\n",
              "      <td>Hill Country Fare Chunky Chicken Corn Chowder ...</td>\n",
              "      <td>Hill Country Fare</td>\n",
              "      <td>Pantry -&gt; Soups &amp; chili</td>\n",
              "      <td>2.340430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>369154</td>\n",
              "      <td>Hill Country Fare Chunky Classic Chicken Noodl...</td>\n",
              "      <td>Hill Country Fare</td>\n",
              "      <td>Pantry -&gt; Soups &amp; chili</td>\n",
              "      <td>1.799685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1287774</td>\n",
              "      <td>Hill Country Fare Hearty Chicken Noodle Soup</td>\n",
              "      <td>Hill Country Fare</td>\n",
              "      <td>Pantry -&gt; Soups &amp; chili</td>\n",
              "      <td>1.662870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10438511</td>\n",
              "      <td>H-E-B Italian-Style Wedding Soup</td>\n",
              "      <td>H-E-B</td>\n",
              "      <td>Pantry -&gt; Soups &amp; chili</td>\n",
              "      <td>1.650160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1417008</td>\n",
              "      <td>Hill Country Fare Hearty Chicken Broccoli Chee...</td>\n",
              "      <td>Hill Country Fare</td>\n",
              "      <td>Pantry -&gt; Soups &amp; chili</td>\n",
              "      <td>1.544112</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-981635f4-f1dd-4b9e-8a04-d2a9878a9241')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-981635f4-f1dd-4b9e-8a04-d2a9878a9241 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-981635f4-f1dd-4b9e-8a04-d2a9878a9241');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ee40f49b-2462-4930-a0b9-831151ab9aa3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ee40f49b-2462-4930-a0b9-831151ab9aa3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ee40f49b-2462-4930-a0b9-831151ab9aa3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  product_id                                               name  \\\n",
              "0    1728263                   H-E-B Organics Tomato Basil Soup   \n",
              "1    1728261                 H-E-B Organics Chicken Noodle Soup   \n",
              "2    1728279     H-E-B Organics Southwest Style Black Bean Soup   \n",
              "3    1728270                         H-E-B Organics Lentil Soup   \n",
              "4    5851502                         H-E-B Hearty Wrangler Soup   \n",
              "5     497561  Hill Country Fare Chunky Chicken Corn Chowder ...   \n",
              "6     369154  Hill Country Fare Chunky Classic Chicken Noodl...   \n",
              "7    1287774       Hill Country Fare Hearty Chicken Noodle Soup   \n",
              "8   10438511                   H-E-B Italian-Style Wedding Soup   \n",
              "9    1417008  Hill Country Fare Hearty Chicken Broccoli Chee...   \n",
              "\n",
              "               brand                 category     score  \n",
              "0              H-E-B  Pantry -> Soups & chili  5.999448  \n",
              "1              H-E-B  Pantry -> Soups & chili  5.985342  \n",
              "2              H-E-B  Pantry -> Soups & chili  5.878461  \n",
              "3              H-E-B  Pantry -> Soups & chili  5.432003  \n",
              "4              H-E-B  Pantry -> Soups & chili  3.576779  \n",
              "5  Hill Country Fare  Pantry -> Soups & chili  2.340430  \n",
              "6  Hill Country Fare  Pantry -> Soups & chili  1.799685  \n",
              "7  Hill Country Fare  Pantry -> Soups & chili  1.662870  \n",
              "8              H-E-B  Pantry -> Soups & chili  1.650160  \n",
              "9  Hill Country Fare  Pantry -> Soups & chili  1.544112  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "import pandas as pd # Import pandas for displaying dataframe\n",
        "import re\n",
        "from openai import OpenAI\n",
        "from typing import List\n",
        "import numpy as np # Import numpy\n",
        "\n",
        "# Retrieve the API key from Colab secrets and set it as an environment variable\n",
        "OPEN_API_KEY = userdata.get('OPEN_API_KEY')\n",
        "os.environ['OPEN_API_KEY'] = OPEN_API_KEY\n",
        "\n",
        "print(\"OPEN_API_KEY loaded into environment variables.\")\n",
        "\n",
        "# Assuming find_queries_file is defined in a previous cell\n",
        "def find_queries_file(preferred=\"queries_synth_test.json\"):\n",
        "    roots = [Path(\".\"), Path(\"/content\"), Path(\"/mnt/data\")]\n",
        "    p = Path(preferred)\n",
        "    if p.exists():\n",
        "        return p.resolve()\n",
        "    for r in roots:\n",
        "        if not r.exists():\n",
        "            continue\n",
        "        for cand in r.rglob(\"queries_synth_train*.*json*\"):\n",
        "            return cand.resolve()\n",
        "    raise FileNotFoundError(\"Couldn't find queries_synth_test*.json — upload it or pass the exact path.\")\n",
        "\n",
        "QPATH = find_queries_file()  # auto-discovers\n",
        "print(\"Queries file:\", QPATH)\n",
        "\n",
        "# Load as [{\"query_id\": \"...\", \"query\": \"...\"}]\n",
        "with open(QPATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    queries_raw = json.load(f)\n",
        "\n",
        "queries = []\n",
        "for j in queries_raw:\n",
        "    qid = j.get(\"query_id\") or j.get(\"qid\") or j.get(\"id\")\n",
        "    qtx = j.get(\"query\") or j.get(\"text\")\n",
        "    if qid and qtx:\n",
        "        queries.append({\"query_id\": str(qid), \"query\": str(qtx)})\n",
        "\n",
        "print(\"Total queries:\", len(queries))\n",
        "print(queries[:3])\n",
        "\n",
        "# Assuming cross_encoder_model, IDX_combined, rowid_to_pid, and meta are loaded from previous steps\n",
        "# If not, load them here:\n",
        "# from sentence_transformers import CrossEncoder\n",
        "# cross_encoder_model_name = 'cross-encoder/ms-marco-MiniLM-L-6-v2'\n",
        "# cross_encoder_model = CrossEncoder(cross_encoder_model_name)\n",
        "# VSTORE = Path(\"vector_store\")\n",
        "# E_combined = np.load(VSTORE/\"emb_combined.npy\")\n",
        "# IDX_combined = build_ip_index(E_combined)\n",
        "# rowid_to_pid = json.loads((VSTORE/\"rowid_to_pid.json\").read_text())\n",
        "# meta = pd.read_parquet(VSTORE/\"products.parquet\")\n",
        "# pid_to_row = {pid: i for i, pid in enumerate(rowid_to_pid)}\n",
        "\n",
        "\n",
        "def search(query_text: str, k_return: int = 10, k_rerank: int = 30,\n",
        "           w_title=0.8, w_brand=0.05, w_cat=0.10, w_desc=0.05):\n",
        "    \"\"\"\n",
        "    1) normalize + embed query once (MiniLM or OpenAI)\n",
        "    2) search the combined index for top-k_rerank candidates\n",
        "    3) re-rank top-k_rerank candidates using a cross-encoder\n",
        "    4) return top-k_return product metadata + re-ranked score\n",
        "    \"\"\"\n",
        "    qn = norm_text(query_text)\n",
        "\n",
        "    # Embed query using OpenAI embeddings\n",
        "    qv_title = embed_texts_openai([qn])  # (1, D)\n",
        "    qv_brand = embed_texts_openai([qn])\n",
        "    qv_cat   = embed_texts_openai([qn])\n",
        "    qv_desc  = embed_texts_openai([qn])\n",
        "\n",
        "    # Concatenate query embeddings with weights\n",
        "    qv_combined = np.concatenate([qv_title * w_title, qv_brand * w_brand, qv_cat * w_cat, qv_desc * w_desc], axis=1)\n",
        "\n",
        "    # top-k_rerank from combined index (scores are cosine/IP because vectors are normalized)\n",
        "    D_combined, I_combined = IDX_combined.search(qv_combined, k_rerank)\n",
        "\n",
        "    # Prepare data for re-ranking\n",
        "    rerank_candidates = []\n",
        "    sentence_pairs = []\n",
        "    for i in I_combined[0]:\n",
        "        pid = rowid_to_pid[i]\n",
        "        m = meta.iloc[i]\n",
        "        product_info = f\"product title: {m['title']} product description: {m['description']}\"\n",
        "        sentence_pairs.append([query_text, product_info])\n",
        "        rerank_candidates.append({\n",
        "            \"product_id\": pid,\n",
        "            \"name\": m[\"title\"],\n",
        "            \"brand\": m[\"brand\"],\n",
        "            \"category\": m[\"category_path\"],\n",
        "            \"original_row_index\": i # Keep track of original index\n",
        "        })\n",
        "\n",
        "    # Predict relevance scores using the cross-encoder model\n",
        "    if sentence_pairs:\n",
        "        rerank_scores = cross_encoder_model.predict(sentence_pairs)\n",
        "        for i, score in enumerate(rerank_scores):\n",
        "            rerank_candidates[i][\"rerank_score\"] = float(score)\n",
        "    else:\n",
        "         # Handle case where no candidates were found\n",
        "        return []\n",
        "\n",
        "\n",
        "    # Sort candidates by re-rank score in descending order\n",
        "    rerank_candidates = sorted(rerank_candidates, key=lambda r: r.get(\"rerank_score\", -float('inf')), reverse=True)\n",
        "\n",
        "    # Return top k_return results\n",
        "    results = []\n",
        "    for i in range(min(k_return, len(rerank_candidates))):\n",
        "        candidate = rerank_candidates[i]\n",
        "        results.append({\n",
        "            \"product_id\": candidate[\"product_id\"],\n",
        "            \"name\": candidate[\"name\"],\n",
        "            \"brand\": candidate[\"brand\"],\n",
        "            \"category\": candidate[\"category\"],\n",
        "            \"score\": candidate[\"rerank_score\"] # Return the re-ranked score\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "# Test the updated search function\n",
        "sample_query = queries[0][\"query\"]\n",
        "top_results = search(sample_query, k_return=10, k_rerank=50)\n",
        "display(pd.DataFrame(top_results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "uu6Bw4WXRgOg",
        "outputId": "068233b8-6a35-4b2a-adc7-be1b629e654a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"display(pd\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"product_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"10438511\",\n          \"1728261\",\n          \"497561\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"H-E-B Italian-Style Wedding Soup\",\n          \"H-E-B Organics Chicken Noodle Soup\",\n          \"Hill Country Fare Chunky Chicken Corn Chowder Soup\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"brand\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Hill Country Fare\",\n          \"H-E-B\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Pantry -> Soups & chili\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.0166620507669273,\n        \"min\": 1.5441118478775024,\n        \"max\": 5.999448299407959,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.6501597166061401\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0b7d860d-c1bf-4927-bfd4-41935eccef04\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>name</th>\n",
              "      <th>brand</th>\n",
              "      <th>category</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1728263</td>\n",
              "      <td>H-E-B Organics Tomato Basil Soup</td>\n",
              "      <td>H-E-B</td>\n",
              "      <td>Pantry -&gt; Soups &amp; chili</td>\n",
              "      <td>5.999448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1728261</td>\n",
              "      <td>H-E-B Organics Chicken Noodle Soup</td>\n",
              "      <td>H-E-B</td>\n",
              "      <td>Pantry -&gt; Soups &amp; chili</td>\n",
              "      <td>5.985342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1728279</td>\n",
              "      <td>H-E-B Organics Southwest Style Black Bean Soup</td>\n",
              "      <td>H-E-B</td>\n",
              "      <td>Pantry -&gt; Soups &amp; chili</td>\n",
              "      <td>5.878461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1728270</td>\n",
              "      <td>H-E-B Organics Lentil Soup</td>\n",
              "      <td>H-E-B</td>\n",
              "      <td>Pantry -&gt; Soups &amp; chili</td>\n",
              "      <td>5.432003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5851502</td>\n",
              "      <td>H-E-B Hearty Wrangler Soup</td>\n",
              "      <td>H-E-B</td>\n",
              "      <td>Pantry -&gt; Soups &amp; chili</td>\n",
              "      <td>3.576779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>497561</td>\n",
              "      <td>Hill Country Fare Chunky Chicken Corn Chowder ...</td>\n",
              "      <td>Hill Country Fare</td>\n",
              "      <td>Pantry -&gt; Soups &amp; chili</td>\n",
              "      <td>2.340430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>369154</td>\n",
              "      <td>Hill Country Fare Chunky Classic Chicken Noodl...</td>\n",
              "      <td>Hill Country Fare</td>\n",
              "      <td>Pantry -&gt; Soups &amp; chili</td>\n",
              "      <td>1.799685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1287774</td>\n",
              "      <td>Hill Country Fare Hearty Chicken Noodle Soup</td>\n",
              "      <td>Hill Country Fare</td>\n",
              "      <td>Pantry -&gt; Soups &amp; chili</td>\n",
              "      <td>1.662870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10438511</td>\n",
              "      <td>H-E-B Italian-Style Wedding Soup</td>\n",
              "      <td>H-E-B</td>\n",
              "      <td>Pantry -&gt; Soups &amp; chili</td>\n",
              "      <td>1.650160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1417008</td>\n",
              "      <td>Hill Country Fare Hearty Chicken Broccoli Chee...</td>\n",
              "      <td>Hill Country Fare</td>\n",
              "      <td>Pantry -&gt; Soups &amp; chili</td>\n",
              "      <td>1.544112</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b7d860d-c1bf-4927-bfd4-41935eccef04')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0b7d860d-c1bf-4927-bfd4-41935eccef04 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0b7d860d-c1bf-4927-bfd4-41935eccef04');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-391313cc-3347-4edb-a873-9377a0b8611e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-391313cc-3347-4edb-a873-9377a0b8611e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-391313cc-3347-4edb-a873-9377a0b8611e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  product_id                                               name  \\\n",
              "0    1728263                   H-E-B Organics Tomato Basil Soup   \n",
              "1    1728261                 H-E-B Organics Chicken Noodle Soup   \n",
              "2    1728279     H-E-B Organics Southwest Style Black Bean Soup   \n",
              "3    1728270                         H-E-B Organics Lentil Soup   \n",
              "4    5851502                         H-E-B Hearty Wrangler Soup   \n",
              "5     497561  Hill Country Fare Chunky Chicken Corn Chowder ...   \n",
              "6     369154  Hill Country Fare Chunky Classic Chicken Noodl...   \n",
              "7    1287774       Hill Country Fare Hearty Chicken Noodle Soup   \n",
              "8   10438511                   H-E-B Italian-Style Wedding Soup   \n",
              "9    1417008  Hill Country Fare Hearty Chicken Broccoli Chee...   \n",
              "\n",
              "               brand                 category     score  \n",
              "0              H-E-B  Pantry -> Soups & chili  5.999448  \n",
              "1              H-E-B  Pantry -> Soups & chili  5.985342  \n",
              "2              H-E-B  Pantry -> Soups & chili  5.878461  \n",
              "3              H-E-B  Pantry -> Soups & chili  5.432003  \n",
              "4              H-E-B  Pantry -> Soups & chili  3.576779  \n",
              "5  Hill Country Fare  Pantry -> Soups & chili  2.340430  \n",
              "6  Hill Country Fare  Pantry -> Soups & chili  1.799685  \n",
              "7  Hill Country Fare  Pantry -> Soups & chili  1.662870  \n",
              "8              H-E-B  Pantry -> Soups & chili  1.650160  \n",
              "9  Hill Country Fare  Pantry -> Soups & chili  1.544112  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Assuming the necessary functions (norm_text, embed_texts_openai, get_openai_client)\n",
        "# and imports (re, OpenAI, os, List, np, pandas, json, Path) are already in the kernel.\n",
        "# If not, they should be included in this cell or ensured from prior cells.\n",
        "\n",
        "# Load the necessary data and index\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "VSTORE = Path(\"vector_store\")\n",
        "\n",
        "# Load combined embeddings\n",
        "E_combined = np.load(VSTORE/\"emb_combined.npy\")\n",
        "\n",
        "# Build in-memory IP index (fast; a few seconds)\n",
        "# Assuming build_ip_index is defined in a previous cell\n",
        "def build_ip_index(emb: np.ndarray):\n",
        "    \"\"\"\n",
        "    Inner-product index. If FAISS is present, use it; otherwise a NumPy fallback\n",
        "    with the same .search(Q, k) API. Assumes emb are L2-normalized.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import faiss   # from faiss-cpu\n",
        "        FAISS_AVAILABLE = True\n",
        "    except Exception:\n",
        "        faiss = None\n",
        "        FAISS_AVAILABLE = False\n",
        "\n",
        "    if FAISS_AVAILABLE:\n",
        "        d = emb.shape[1]\n",
        "        index = faiss.IndexFlatIP(d)\n",
        "        index.add(emb.astype(\"float32\"))\n",
        "        return index\n",
        "\n",
        "    class NumpyIPIndex:\n",
        "        def __init__(self, X):\n",
        "            self.X = X.astype(\"float32\")\n",
        "        def add(self, X):\n",
        "            pass\n",
        "        def search(self, Q, k):\n",
        "            S = Q @ self.X.T\n",
        "            I = np.argpartition(-S, k-1, axis=1)[:, :k]\n",
        "            S_topk = np.take_along_axis(S, I, axis=1)\n",
        "            order = np.argsort(-S_topk, axis=1)\n",
        "            I_sorted = np.take_along_axis(I, order, axis=1)\n",
        "            D_sorted = np.take_along_axis(S_topk, order, axis=1)\n",
        "            return D_sorted.astype(\"float32\"), I_sorted.astype(\"int64\")\n",
        "    return NumpyIPIndex(emb)\n",
        "\n",
        "IDX_combined = build_ip_index(E_combined)\n",
        "\n",
        "# Load ID map and metadata\n",
        "rowid_to_pid = json.loads((VSTORE/\"rowid_to_pid.json\").read_text())\n",
        "meta = pd.read_parquet(VSTORE/\"products.parquet\")\n",
        "\n",
        "# Assuming cross_encoder_model and queries are loaded from previous cells\n",
        "\n",
        "# Test the updated search function\n",
        "sample_query = queries[0][\"query\"]\n",
        "top_results = search(sample_query, k_return=10, k_rerank=50)\n",
        "display(pd.DataFrame(top_results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCZVaBZgCgEj",
        "outputId": "2ca34db6-98f6-448b-f95e-563bf6a9c203"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting re-ranking for 288 queries...\n",
            "  Processing query 1/288: hearty organic soups for dinner...\n",
            "  Processing query 50/288: natural boneless pork...\n",
            "  Processing query 100/288: wild caught tuna in olive oil...\n",
            "  Processing query 150/288: minimally processed pork chunks...\n",
            "  Processing query 200/288: H-E-B whole roasting chicken...\n",
            "  Processing query 250/288: quick dinner chicken kabobs...\n",
            "  Processing query 288/288: quick chicken fajita meal...\n",
            "Finished re-ranking 288 queries in 399.13 seconds.\n",
            "Generated 8640 re-ranked results.\n",
            "First 5 re-ranked results: [{'query_id': 's334', 'rank': 1, 'product_id': '1728263'}, {'query_id': 's334', 'rank': 2, 'product_id': '1728261'}, {'query_id': 's334', 'rank': 3, 'product_id': '1728279'}, {'query_id': 's334', 'rank': 4, 'product_id': '1728270'}, {'query_id': 's334', 'rank': 5, 'product_id': '5851502'}]\n",
            "Writing re-ranked submission to submission_reranked.json...\n",
            "Wrote re-ranked submission: submission_reranked.json\n",
            "Original submission file not found. Skipping comparison.\n"
          ]
        }
      ],
      "source": [
        "from typing import List, Dict\n",
        "import json\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from sklearn.metrics import average_precision_score, precision_score, recall_score\n",
        "from collections import defaultdict\n",
        "import time # Import time for logging duration\n",
        "\n",
        "def rank_all_queries_topk_reranked(queries: List[Dict], k: int = 30) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Runs the re-ranked search() for each query and returns a flat list like:\n",
        "    [\n",
        "      {\"query_id\": \"s181\", \"rank\": 1, \"product_id\": \"6033004\"},\n",
        "      ...\n",
        "    ]\n",
        "    \"\"\"\n",
        "    output = []\n",
        "    print(f\"Starting re-ranking for {len(queries)} queries...\")\n",
        "    start_time = time.time()\n",
        "    for i, q in enumerate(queries):\n",
        "        qid, qtext = q[\"query_id\"], q[\"query\"]\n",
        "        if (i + 1) % 50 == 0 or i == 0 or i == len(queries) - 1:\n",
        "             print(f\"  Processing query {i+1}/{len(queries)}: {qtext[:50]}...\")\n",
        "\n",
        "\n",
        "        # Get top-k candidates from the re-ranked search\n",
        "        # Use k_rerank=100 for the initial retrieval and k_return=k for the final results\n",
        "        results = search(qtext, k_return=k, k_rerank=100) # Changed k_rerank to 100\n",
        "\n",
        "        # Tie-break by product_id for deterministic order (already sorted by score desc in search)\n",
        "        results = sorted(results, key=lambda r: (-r[\"score\"], str(r[\"product_id\"])))\n",
        "\n",
        "        # Flatten with ranks\n",
        "        for rank, r in enumerate(results, start=1):\n",
        "            output.append({\n",
        "                \"query_id\": qid,\n",
        "                \"rank\": rank,\n",
        "                \"product_id\": str(r[\"product_id\"]),\n",
        "            })\n",
        "    end_time = time.time()\n",
        "    print(f\"Finished re-ranking {len(queries)} queries in {end_time - start_time:.2f} seconds.\")\n",
        "    return output\n",
        "\n",
        "# Use the training queries loaded previously\n",
        "# queries = load_queries_any(qpath) # assuming qpath is defined and contains the path to the training queries\n",
        "\n",
        "flat_topk_reranked = rank_all_queries_topk_reranked(queries, k=30) # Explicitly setting k=30\n",
        "print(f\"Generated {len(flat_topk_reranked)} re-ranked results.\")\n",
        "print(\"First 5 re-ranked results:\", flat_topk_reranked[:5])\n",
        "\n",
        "\n",
        "# Generate submission file for re-ranked results\n",
        "OUT_FILE_RERANKED = \"submission_reranked.json\"\n",
        "print(f\"Writing re-ranked submission to {OUT_FILE_RERANKED}...\")\n",
        "with open(OUT_FILE_RERANKED, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(flat_topk_reranked, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"Wrote re-ranked submission:\", OUT_FILE_RERANKED)\n",
        "\n",
        "# Load the original submission file (if it exists) for comparison\n",
        "# Assuming the original submission file is named \"submission.json\"\n",
        "original_submission_file = \"submission.json\"\n",
        "original_results = []\n",
        "if Path(original_submission_file).exists():\n",
        "    print(f\"Loading original submission from {original_submission_file}...\")\n",
        "    with open(original_submission_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        original_results = json.load(f)\n",
        "    print(\"Loaded original submission:\", original_submission_file)\n",
        "else:\n",
        "    print(\"Original submission file not found. Skipping comparison.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}